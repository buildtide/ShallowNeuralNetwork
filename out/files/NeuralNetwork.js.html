<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>NeuralNetwork.js</title>
    <link rel="stylesheet" href="http://yui.yahooapis.com/3.9.1/build/cssgrids/cssgrids-min.css">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="../assets/css/main.css" id="site_styles">
    <link rel="icon" href="../assets/favicon.ico">
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body class="yui3-skin-sam">

<div id="doc">
    <div id="hd" class="yui3-g header">
        <div class="yui3-u-3-4">
                <h1><img src="../assets/css/logo.png" title="" width="117" height="52"></h1>
        </div>
        <div class="yui3-u-1-4 version">
            <em>API Docs for: </em>
        </div>
    </div>
    <div id="bd" class="yui3-g">

        <div class="yui3-u-1-4">
            <div id="docs-sidebar" class="sidebar apidocs">
                <div id="api-list">
                    <h2 class="off-left">APIs</h2>
                    <div id="api-tabview" class="tabview">
                        <ul class="tabs">
                            <li><a href="#api-classes">Classes</a></li>
                            <li><a href="#api-modules">Modules</a></li>
                        </ul>
                
                        <div id="api-tabview-filter">
                            <input type="search" id="api-filter" placeholder="Type to filter APIs">
                        </div>
                
                        <div id="api-tabview-panel">
                            <ul id="api-classes" class="apis classes">
                                <li><a href="../classes/NeuralNetwork.html">NeuralNetwork</a></li>
                            </ul>
                
                
                            <ul id="api-modules" class="apis modules">
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="yui3-u-3-4">
                <div id="api-options">
                    Show:
                    <label for="api-show-inherited">
                        <input type="checkbox" id="api-show-inherited" checked>
                        Inherited
                    </label>
            
                    <label for="api-show-protected">
                        <input type="checkbox" id="api-show-protected">
                        Protected
                    </label>
            
                    <label for="api-show-private">
                        <input type="checkbox" id="api-show-private">
                        Private
                    </label>
                    <label for="api-show-deprecated">
                        <input type="checkbox" id="api-show-deprecated">
                        Deprecated
                    </label>
            
                </div>
            
            <div class="apidocs">
                <div id="docs-main">
                    <div class="content">
<h1 class="file-heading">File: NeuralNetwork.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
Copyright (c) 2015-2016 Hussain Mir Ali
**/
&quot;use strict&quot;;

var window_object = (function(g){
      return g;
  }(this));

/**
 * The NeuralNetwork class contains all the necessary logic to train data for multiclass classification using single layer Neural Network.
 *
 * @class NeuralNetwork
 * @constructor
 * @param {Object} args Contains all the necessary parameters for the neural network as listed below.
 * @param {Number} args.learningRate Learning rate for BackPropogation.
 * @param {Number} args.threshold_value Optional threshold value for error. 
 * @param {Number} args.regularization_parameter Optional regularization parameter to prevent overfitting. 
 * @param {Number} args.notify_count Optional value to execute the iteration_callback after every x number of iterations.
 * @param {Function} args.iteration_callback Optional callback that can be used for getting cost and iteration value on every notify count.
 * @param {Number} args.hiddenLayerSize Optional value for number of hidden layer units.
 * @param {Number} args.maximum_iterations Optional maximum iterations to be allowed before the optimization is complete. 
 * @param {Object} args.optimization_mode Optional optimzation(gradient descent) mode. For batch gradient descent optimization_mode =  {&#x27;mode&#x27;: 0} and for mini-batch gradient descent optimization_mode =  {&#x27;mode&#x27;: 1, &#x27;batch_size&#x27;: (specify  required size) }. 
 **/

var NeuralNetwork = function(args) {
    if(Object.keys(window_object).length === 0){
        this.MathJS = require(&#x27;mathjs&#x27;);
        this.q = require(&#x27;q&#x27;);
    }
    else{
        this.MathJS = math;
        this.q = Q;
    }
  this.initArgs = args;
  this.threshold = args.threshold || (1 / this.MathJS.exp(3));
  this.algorithm_mode = 0;
  this.iteration_callback = args.iteration_callback;
  this.hiddenLayerSize = args.hiddenLayerSize;
  this.regularization_param = args.regularization_param || 0.01;
  this.learningRate = args.learningRate || 0.5;
  this.optimization_mode = (args.optimization_mode === undefined) ? {
    &#x27;mode&#x27;: 0
  } : args.optimization_mode;
  this.maximum_iterations = args.maximum_iterations || 1000;
  this.batch_iteration_count = 0;
  this.notify_count = args.notify_count || 100;
};

/**
 * This method returns all the parameters passed to the constructor.
 *
 * @method getInitParams
 * @return {Object} Returns the constructor parameters.
 */

NeuralNetwork.prototype.getInitParams = function() {
  return {
    &#x27;algorithm_mode&#x27;: this.algorithm_mode,
    &#x27;hiddenLayerSize&#x27;: this.hiddenLayerSize,
    &#x27;optimization_mode&#x27;: this.optimization_mode,
    &#x27;notify_count&#x27;: this.notify_count,
    &#x27;iteration_callback&#x27;: this.iteration_callback,
    &#x27;threshold&#x27;: this.threshold,
    &#x27;regularization_param&#x27;: this.regularization_param,
    &#x27;learningRate&#x27;: this.learningRate,
    &#x27;maximum_iterations&#x27;: this.maximum_iterations
  };
};

/**
 * This method serves as the logic for the sigmoid function.
 *
 * @method sigmoid
 * @param {matrix} z The matrix to be used as the input for the sigmoid function. 
 * @return {matrix} Returns the elementwise sigmoid of the input matrix.
 */

NeuralNetwork.prototype.sigmoid = function(z) {
  var scope = {
      z: (typeof(z) === &quot;number&quot;) ? this.MathJS.matrix([
        [z]
      ]) : z
    },
    sigmoid;
  if (scope.z.size()[1] === undefined)
    scope.ones = this.MathJS.ones(scope.z.size()[0]);
  else
    scope.ones = this.MathJS.ones(scope.z.size()[0], scope.z.size()[1]);
  sigmoid = this.MathJS.eval(&#x27;(ones+(e.^(z.*-1))).^-1&#x27;, scope); //1/(1+e^(-z))
  return sigmoid;
};

/**
 *This method is responsible for the forwardPropagation in the Neural Network.
 *
 * @method forwardPropagation 
 * @param {matrix} X The input matrix representing the features.
 * @param {matrix} W1 The matrix representing the weights for layer 1.
 * @param {matrix} W2 The matrix representing the weights for layer 2.
 * @return {matrix} Returns the resultant ouput of forwardPropagation.
 */
NeuralNetwork.prototype.forwardPropagation = function(X, W1, W2) {
  var y_result, X = this.MathJS.matrix(X) || this.x, scope = {};
  this.W1 = W1 || this.W1;
  this.W2 = W2 || this.W2;
  this.z2 = this.MathJS.multiply(X, this.W1);
  scope.z2 = this.z2;
  this.z2 = this.MathJS.eval(&#x27;z2+1&#x27;, scope);
  this.a2 = this.sigmoid(this.z2);
  this.z3 = this.MathJS.multiply(this.a2, this.W2);
  scope.z3 = this.z3;
  this.z3 = this.MathJS.eval(&#x27;z3+1&#x27;, scope);
  y_result = this.sigmoid(this.z3);
  return y_result;
};

/**
 * This method serves as the logic for the sigmoid function derivative.
 *
 * @method sigmoid_Derivative
 * @param {matrix} z The matrix to be used as the input for the sigmoid function derivative. 
 * @return {matrix} Returns the elementwise sigmoid derivative of the input matrix.
 */
NeuralNetwork.prototype.sigmoid_Derivative = function(z) {
  var scope = {
      z: z
    },
    sigmoid_Derivative;
  scope.ones = this.MathJS.ones(z.size()[0], z.size()[1]);
  sigmoid_Derivative = this.MathJS.eval(&#x27;(e.^(z.*-1))./(ones+(e.^(z.*-1))).^2&#x27;, scope); //(1+e^(-z))/(1+e^(-z))^2

  return sigmoid_Derivative;
};

/**
 *This method is responsible for the costFunction, i.e. error.
 *
 * @method costFunction 
 * @param {matrix} X The input matrix representing the features.
 * @param {matrix} Y The output matrix corresponding to training data.
 * @param {Number} algorithm_mode The current algorithm mode (testing: 2, crossvalidating: 1, training: 0).
 * @return {Number} Returns the resultant cost.
 */
NeuralNetwork.prototype.costFunction = function(X, Y, algorithm_mode) {
  var J, batch_size;
  var scope = {};
  var iteration_count;

  scope.y = this.MathJS.matrix(Y);
  scope.x = this.MathJS.matrix(X);
  scope.W1 = this.W1;
  scope.W2 = this.W2;
  this.algorithm_mode = algorithm_mode || this.algorithm_mode;

  this.batch_iteration_count++;
  iteration_count = this.batch_iteration_count;

  if (this.optimization_mode.mode === 1) { //cost for mini-batch gradient descent.
    batch_size = this.optimization_mode.batch_size;

    scope.x = this.MathJS.matrix(scope.x._data.slice(batch_size * iteration_count, batch_size + (batch_size * iteration_count)));
    scope.y = this.MathJS.matrix(scope.y._data.slice(batch_size * iteration_count, batch_size + (batch_size * iteration_count)));

    if (iteration_count * this.optimization_mode.batch_size === scope.x.size()[0]) {
      this.batch_iteration_count = 0;
    }

    this.y_result = this.forwardPropagation(scope.x, undefined, undefined);
    scope.y_result = this.y_result;

    if (this.algorithm_mode === 0)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope)) / (this.optimization_mode.batch_size) + (this.regularization_param / 2) * (this.MathJS.sum(this.MathJS.eval(&#x27;W1.^2&#x27;, scope)) + this.MathJS.sum(this.MathJS.eval(&#x27;W2.^2&#x27;, scope))); //cost with regularization parameter.
    else if (this.algorithm_mode === 1 || this.algorithm_mode === 2)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope)) / (this.optimization_mode.batch_size);
  } else if (this.optimization_mode.mode === 2 &amp;&amp; (iteration_count &lt;= scope.x.size()[0])) { // cost for stochastic gradient descent.
    scope.x = this.MathJS.matrix(scope.x._data[iteration_count - 1]);
    scope.y = this.MathJS.matrix(scope.y._data[iteration_count - 1]);

    this.y_result = this.forwardPropagation(scope.x, undefined, undefined);
    scope.y_result = this.y_result;

    if (this.algorithm_mode === 0)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope)) + (this.regularization_param / 2) * (this.MathJS.sum(this.MathJS.eval(&#x27;W1.^2&#x27;, scope)) + this.MathJS.sum(this.MathJS.eval(&#x27;W2.^2&#x27;, scope))); //cost with regularization parameter.
    else if (this.algorithm_mode === 1 || this.algorithm_mode === 2)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope));
  } else if (this.optimization_mode.mode === 0) { //cost with batch gradient descent.
    this.y_result = this.forwardPropagation(scope.x, undefined, undefined);
    scope.y_result = this.y_result;

    if (this.algorithm_mode === 0)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope)) / (scope.x.size()[0]) + (this.regularization_param / 2) * (this.MathJS.sum(this.MathJS.eval(&#x27;W1.^2&#x27;, scope)) + this.MathJS.sum(this.MathJS.eval(&#x27;W2.^2&#x27;, scope))); //cost with regularization parameter.
    else if (this.algorithm_mode === 1 || this.algorithm_mode === 2)
      J = this.MathJS.sum(this.MathJS.eval(&#x27;0.5*((y-y_result).^2)&#x27;, scope)) / (scope.x.size()[0]);

  }

  return J;
};

/**
 *This method is responsible for the costFunction_Derivative, i.e. gradient of error with respect to weights.
 *
 * @method costFunction_Derivative 
 * @param {matrix} X The input matrix representing the features.
 * @param {matrix} Y The output matrix corresponding to training data.
 * @param {matrix} W1 The matrix representing the weights for layer 1.
 * @param {matrix} W2 The matrix representing the weights for layer 2.
 * @return {Array} Returns the resultant gradients with respect to layer 1: dJdW1 and layer 2: dJdW2 of the Neural Network.
 */

NeuralNetwork.prototype.costFunction_Derivative = function(X, Y, W1, W2) {
  if (this.optimization_mode.mode === 1) {

    var iteration_count = this.batch_iteration_count;
    var batch_size = this.optimization_mode.batch_size;
    var X = this.MathJS.matrix(this.x._data.slice(batch_size * iteration_count, batch_size + (batch_size * iteration_count)));
    var Y = this.MathJS.matrix(this.y._data.slice(batch_size * iteration_count, batch_size + (batch_size * iteration_count)));

  }

  this.y_result = this.forwardPropagation(X || this.x, undefined, undefined);
  var scope = {};
  scope.y_result = this.y_result;
  scope.y = Y || this.y;
  scope.x = X || this.x;
  scope.diff = this.MathJS.eval(&#x27;-(y-y_result)&#x27;, scope);
  scope.sigmoid_Derivative_z3 = this.sigmoid_Derivative(this.z3);
  scope.regularization_param = this.regularization_param;
  scope.W2 = W2 || this.W2;
  scope.W1 = W1 || this.W1;
  scope.m = scope.x.size()[0];

  var del_3 = this.MathJS.eval(&#x27;diff.*sigmoid_Derivative_z3&#x27;, scope);
  var dJdW2 = this.MathJS.multiply(this.MathJS.transpose(this.a2), del_3);
  scope.dJdW2 = dJdW2;
  scope.regularization_term_dJdW2 = this.MathJS.eval(&#x27;W2.*regularization_param&#x27;, scope);
  dJdW2 = this.MathJS.eval(&#x27;dJdW2.*(1/m) + regularization_term_dJdW2&#x27;, scope);

  scope.arrA = this.MathJS.multiply(del_3, this.MathJS.transpose(this.W2));
  scope.arrB = this.sigmoid_Derivative(this.z2);

  var del_2 = this.MathJS.eval(&#x27;arrA.*arrB&#x27;, scope);
  var dJdW1 = this.MathJS.multiply(this.MathJS.transpose(scope.x), del_2);

  scope.dJdW1 = dJdW1;
  scope.regularization_term_dJdW1 = this.MathJS.eval(&#x27;W1.*regularization_param&#x27;, scope);
  dJdW1 = this.MathJS.eval(&#x27;dJdW1.*(1/m) + regularization_term_dJdW1&#x27;, scope);

  return [dJdW1, dJdW2];

};

/**
 *This method is responsible for saving the trained weights of the Neural Network.
 *
 * @method saveWeights 
 * @param {Array} weights The weights of the layer1 and layer2 of the Neural Network.
 * @return {Boolean} Returns true after succesfuly saving the weights.
 */
NeuralNetwork.prototype.saveWeights = function(weights) {
  var defered = this.q.defer();
  if(Object.keys(window_object).length === 0){
    global.localStorage.setItem(&quot;Weights&quot;, weights);
  }
  else{
    localStorage.setItem(&quot;Weights&quot;, weights);
  }
  console.log(&quot;\nWeights were successfuly saved.&quot;);
  return true;
};

/**
 *This method is responsible for the optimization of weights, i.e. BackPropagation algorithm.
 *
 * @method gradientDescent
 * @param {matrix} X The input matrix representing the features.
 * @param {matrix} Y The output matrix corresponding to training data.
 * @param {matrix} W1 The matrix representing the weights for layer 1.
 * @param {matrix} W2 The matrix representing the weights for layer 2.
 * @return {Object} Returns a resolved promise with iteration and cost data on successful completion of optimization. 
 */
NeuralNetwork.prototype.gradientDescent = function(X, Y, W1, W2) {
  var gradient = new Array(2),
    self = this,
    x = X || this.x,
    y = Y || this.y,
    W1 = W1,
    W2 = W2,
    cost,
    scope = {},
    defered = this.q.defer(),
    i = 1;

  if (this.algorithm_mode == 0)
    console.log(&#x27;Training ...\n&#x27;);

  while (true) {

    if (x !== undefined &amp;&amp; y !== undefined &amp;&amp; W1 !== undefined &amp;&amp; W2 !== undefined)
      gradient = this.costFunction_Derivative(x, y, W1, W2);
    else
      gradient = this.costFunction_Derivative(undefined, undefined, undefined, undefined);
    scope.W1 = W1 || this.W1;
    scope.W2 = W2 || this.W2;
    scope.rate = this.learningRate;
    scope.dJdW1 = gradient[0];
    scope.dJdW2 = gradient[1];

    this.W2 = this.MathJS.eval(&#x27;W2 - dJdW2.*rate&#x27;, scope);
    this.W1 = this.MathJS.eval(&#x27;W1 - dJdW1.*rate&#x27;, scope);

    if (x !== undefined &amp;&amp; y !== undefined)
      cost = this.costFunction(x, y, undefined);
    if (i % this.notify_count === 0 &amp;&amp; this.iteration_callback !== undefined) {
      this.iteration_callback.apply(null, [{
        &#x27;cost&#x27;: cost,
        &#x27;iteration&#x27;: i /*iteration count*/ ,
        &#x27;Weights_Layer1&#x27;: self.W1,
        &#x27;Weights_Layer2&#x27;: self.W2
      }]); //notify cost values for diagnosing the performance of learning algorithm.
    }
    i++;
    if (i &gt; this.maximum_iterations || cost &lt;= (this.threshold)) {
      this.saveWeights([this.W1, this.W2]);
      defered.resolve([cost, i]);
      break;
    }
  }

  return defered.promise;
};

/**
 *This method is responsible for creating layers and initializing random weights. 
 *
 * @method train_network
 * @param {matrix} X The input matrix representing the features of the training set.
 * @param {matrix} Y The output matrix corresponding to training set data.
 * @return {Object} Returns a resolved promise with iteration and cost data on successful completion of optimization. 
 */
NeuralNetwork.prototype.train_network = function(X, Y) {
  this.x = this.MathJS.matrix(X);
  this.y = this.MathJS.matrix(Y);
  this.algorithm_mode = 0;

  if ((this.y.size()[0] !== this.x.size()[0])) {
    console.log(&#x27;\nPlease change the size of the input matrices so that X and Y have same number of rows.&#x27;);
  } else {
    this.inputLayerSize = this.x.size()[1];
    this.outputLayerSize = 1;
    if (this.hiddenLayerSize !== undefined) {
      if (this.hiddenLayerSize &gt;= this.x.size()[1] + 1)
        this.hiddenLayerSize = this.hiddenLayerSize;
      else
        this.hiddenLayerSize = this.x.size()[1] + 1;
    } else if (this.hiddenLayerSize === undefined)
      this.hiddenLayerSize = this.x.size()[1] + 1;

    this.W1 = (this.MathJS.random(this.MathJS.matrix([this.inputLayerSize, this.hiddenLayerSize]), -10, 10));
    this.W2 = (this.MathJS.random(this.MathJS.matrix([this.hiddenLayerSize, this.outputLayerSize * this.y.size()[1]]), -10, 10));
  }
  return this.gradientDescent(undefined, undefined, undefined, undefined);
};

/**
 *This contains logic to predict result for a given input after training on data. 
 *
 * @method predict_result
 * @param {matrix} X The input matrix representing the features.
 * @return {matrix} Returns the resultant matrix after performing forwardPropagation on saved weights.
 */

NeuralNetwork.prototype.predict_result = function(X) {
  var y_result;
  this.setWeights();
  y_result = this.forwardPropagation(X);
  return y_result;
};

/**
 *This method is responsible for setting weights of the Neural Network.
 *
 * @method setWeights 
 * @return {Object} Returns a resolved promise after successfuly setting weights.
 */
NeuralNetwork.prototype.setWeights = function() {
  var contents_layer1, contents_layer2;
  var self = this,
    success;

  var self = this;
  var weights;
    if(Object.keys(window_object).length === 0){
       weights = global.localStorage.getItem(&quot;Weights&quot;);
    }else{
       weights = localStorage.getItem(&quot;Weights&quot;);
     }

     self.W1 = weights[0];
     self.W2 = weights[1];

     return [self.W1, self.W2];
};

/**
 *This method is responsible for producing the cross validation error after training data.
 *
 * @method cross_validate_network
 * @param {matrix} X The input matrix representing the features of the cross validation set.
 * @param {matrix} Y The output matrix corresponding to training data of the cross validation set.
 * @return {Number} Returns an error value associated with the cross validation.
 */
NeuralNetwork.prototype.cross_validate_network = function(X, Y) {
  console.log(&quot;\n Cross Validating...&quot;);
  this.algorithm_mode = 1;
  return this.costFunction(X, Y, undefined);
};

/**
 *This method is responsible for producing the test error after training data.
 *
 * @method test_network
 * @param {matrix} X The input matrix representing the features of the test set.
 * @param {matrix} Y The output matrix corresponding to training data of the test set.
 * @return {Number} Returns an error value associated with testing.
 */
NeuralNetwork.prototype.test_network = function(X, Y) {
  console.log(&quot;\n Testing...&quot;);
  this.algorithm_mode = 2;
  return this.costFunction(X, Y, undefined);
};

if(Object.keys(window_object).length === 0){
    module.exports = NeuralNetwork;
}else{
    window[&#x27;Autoencoder&#x27;] = NeuralNetwork;
}
    </pre>
</div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
